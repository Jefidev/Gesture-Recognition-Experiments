# LSFB-25 first results 

This repository contains the code of various experiments performed to assess the performance of various deep learning architecture and machine learning models for sign language recognition.


## Models
- **CNN + RNN** : Model computing the VGG16 embedding for each frame of the video and feeding them to a RNN networks in order to classify signs
- **C3D** : 3D convulition model for video recogniton
- **I3D** : Inflated convolutionnal network cloned from https://github.com/piergiaj/pytorch-i3d
- **Two-Stream networks** : TODO
- **Visual Bags of Words for Video** : Visual Bag of Words


## Model to try

state of the art for action recognition on UCF-101